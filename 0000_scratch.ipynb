{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:174: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  UserWarning,\n",
      "C:\\Users\\carna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:174: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3362\n",
      "           1       1.00      1.00      1.00      2936\n",
      "\n",
      "    accuracy                           1.00      6298\n",
      "   macro avg       1.00      1.00      1.00      6298\n",
      "weighted avg       1.00      1.00      1.00      6298\n",
      "\n",
      "ROC AUC: 0.9999159138763581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:174: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  UserWarning,\n",
      "C:\\Users\\carna\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:174: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ðŸŒ³ Final Random Forest Model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Load training and test data\n",
    "data = pd.read_csv('./data/train_data.csv')\n",
    "test_data = pd.read_csv('./data/test_data.csv')\n",
    "\n",
    "# Define column groups\n",
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "drop_cols = ['num_outbound_cmds', 'is_host_login']\n",
    "label_col = 'class'\n",
    "\n",
    "# Drop unnecessary columns from training data\n",
    "data = data.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Ensure categorical columns are string\n",
    "for col in categorical_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype('string')\n",
    "\n",
    "# Encode label\n",
    "data[label_col] = data[label_col].map({'normal': 0, 'anomaly': 1})\n",
    "\n",
    "# Split features and label\n",
    "X = data.drop(columns=[label_col])\n",
    "y = data[label_col]\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42069)\n",
    "\n",
    "# Build preprocessing pipeline\n",
    "cat_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', cat_transformer, categorical_cols)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',\n",
    "        random_state=42069,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation split\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "y_test_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "print(\"Validation Results:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_test_proba))\n",
    "\n",
    "# === APPLY TO TEST SET ===\n",
    "# Drop columns and set categorical types\n",
    "test_data = test_data.drop(columns=drop_cols, errors='ignore')\n",
    "for col in categorical_cols:\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = test_data[col].astype('string')\n",
    "\n",
    "# Predict on new test data\n",
    "test_preds = pipeline.predict(test_data)\n",
    "test_proba = pipeline.predict_proba(test_data)[:, 1]\n",
    "\n",
    "# If ground truth available\n",
    "if 'class' in test_data.columns:\n",
    "    y_true = test_data['class'].map({'normal': 0, 'anomaly': 1})\n",
    "    print(\"Test Data Results:\")\n",
    "    print(classification_report(y_true, test_preds))\n",
    "    print(\"Test ROC AUC:\", roc_auc_score(y_true, test_proba))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
